---
title: "Importing and preprocessing raw m-Path data with mpathr"
date: "`r Sys.Date()`"
author: "Lara Navarrete and Koen Niemeijer"
output:
  html_document:
    theme: cerulean
    highlight: pygments
    smart: true
    toc: true
    toc_float: true
    toc_depth: "2"
    code_folding: "show"
    code_download: true
    code_copy: true
    df_print: tibble
    css: styles.css
    includes:
      in_header: header.html
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  cache = FALSE,
  highlight = TRUE,
  fig.width = 9,
  fig.align = "center",
  comment = "#>",
  tidy = "styler",
  tidy.opts = list(
    arrow = TRUE,
    indent = 2,
    width.cutoff = 80
  )
)
```

```{css, echo=FALSE}
.scrollable {
  max-height: 500px;
  overflow-y: auto;
  background-color: inherit;
}
```


This guide implements the preprocessing of an example dataset gathered with [m-Path](https://m-Path.io/landing/) and loaded with its companion R package `mpathr`. m-Path is a platform that allows researchers to create and deploy Experience Sampling Method (ESM) studies. ESM studies are a type of longitudinal study where participants are prompted to answer questions about their emotions, activities, and context in real-time. 

The dataset consists of the resulting data from an ESM experiment, from 20 participants collected over the course of 10 days. Participants completed the following questionnaires:

* Intake questionnaire: where participants consented to participate and filled the Neuroticism subscale of the Big Five Inventory (BFI) and the Satisfaction with Life Scale (SWLS).
* Main questionnaire (administered 10 times per day): Participants answered questions about their emotions and activities.
* Evening questionnaire (every evening): where participants  rated their emotions throughout the day.

The dataset is available through the `mpath_example()` function in `mpathr` but can also be downloaded separately from Github [here](https://github.com/m-path-io/mpathr/tree/master/inst/extdata).

This guide builds upon the framework, R tutorials, and templates for preprocessing ESM data developed by Revol et al. (2024). These resources are detailed in the associated [paper](https://journals.sagepub.com/doi/full/10.1177/25152459241256609) and the [ESM Preprocessing Gallery](https://preprocess.esmtools.com/) website. When using this work, please cite the following paper: 

* Revol, J., Carlier, C., Lafit, G., Verhees, M., Sels, L., & Ceulemans, E. (2024). Preprocessing Experience-Sampling-Method Data: A Step-by-Step Framework, Tutorial Website, R Package, and Reporting Templates. _Advances in Methods and Practices in Psychological Science_, 7(4), 1â€“18. https://doi.org/10.1177/25152459241256609.


## Set up

We will start by loading the packages that we will use in this analysis. Since this guide requires the installation of a good number of packages, the following code automatically installs packages that are not already installed. Packages are loaded whenever these are needed in the guide.

```{r, warning=FALSE, message=FALSE}
required_packages <- c(
  "mpathr", "esmtools", "skimr", "dplyr", "tidyr", "visdat", "lubridate", "ggplot2", 
  "gglalt", "scales", "lme4", "performance", "car", "modelbased", "rsq"
)

# checks which of the packages are installed and installs the ones that are not
install.packages(setdiff(required_packages, rownames(installed.packages())))

# create m-Path palettes (for plotting):
ggplot2::theme_set(ggplot2::theme_bw())

# Colors for the plots in this guide
mpath_palette <- c("#2196F3", "#F33920", "#F4A222")
dark_mpath_palette <- c("#087DDA", "#DA2006", "#DB8908")
```

# Step 1: Importing data and preliminary preprocessing

In this step, we will import the data and perform some preliminary preprocessing. We first take a look at the data, and then we clean it by renaming columns and making composite variables. We then check for duplicated and missing variables, and finally reformat the time stamps and create new time variables.

## Importing
To read the `basic.csv` as exported from m-Path, we can use the `read_mpath()` function, that takes as arguments the path to the data (`file`) and the path to the meta data (`meta_data`), and returns the data as a data frame. The metadata contains information about how the data should be read, this information is used by the `read_mpath()` function to get the correct data types. In this guide, we will use the example data that comes with the `mpathr` package, which can be found by calling `mpath_example()`.

```{r read m-Path data}
library(mpathr)

data <- read_mpath(
  file = mpath_example("example_basic.csv"), # path to the data 
  meta_data = mpath_example("example_meta.csv") # path to the metadata
) 
```

## Note: saving m-Path data

The resulting data frame will contain columns with lists,
which can be problematic when saving the data. To save the data, we suggest the
following two options:

If you want to save the data as a comma-separated values (CSV) file to use it in another program, 
use `write_mpath()`. This function will collapse most list columns to a single string and parses
all character columns to JSON strings, essentially reversing the operations performed by 
`read_mpath()`. Note that this does not mean that data can be read back using `read_mpath()`,
because the data may have been modified and thus no longer be in line with the meta data.

```{r write data as csv, eval = FALSE}
write_mpath(
  x = data,
  file = "data.csv"
)
```

Otherwise, if the data will be used exclusively in R, we suggest saving it as an R object (`.RData` 
or `.RDS`):
```{r write data as an R object, eval = FALSE}
# As an .RData file. When using `load()`, note that the data will be stored in the `data`
# object in the global environment.
save(
  data, 
  file = "data.RData"
)

# As an RDS file.
saveRDS(
  data, 
  file = "data.RDS"
)
```

## First glimpse
We can first check the data to get a better idea of what we are working with. 

**Meta-info of the ESM dataset.** 
The `dataInfo()` function from the `esmtools` package provides some useful information, such as the number of columns and rows, the number of participants, the number of observations per participant, and the number of missing values.

```{r print data info, class.output="scrollable"}
library(esmtools)

dataInfo(
  file_path = mpath_example("example_basic.csv"),
  read_fun = read.csv2,
  idvar = "connectionId", # specify the participant variable
  timevar = "timeStampSent" # specify the time variable
)
```
We can see that we have `r length(unique(data$connectionId))` participants, and we have `r nrow(data)/length(unique(data$connectionId))` observations per participant.

We can also print the data and use the `skim()` function from the `skimr` package to get a summary of the data.

```{r modify print.skim_df, echo = FALSE}
print.skim_df <- function(x, ...) {
  skimr:::print.skim_df(x, width = 90, n = 10)
}
```

```{r print data and skim}
library(skimr)

head(data) # prints first rows of df

print(skim(data)) # prints summary of df
```
From the output of the `skim` function, we can see that we don"t have any missing values in `connectionId` (our participant identifier variable), and also in the time variable `timeStampSent`. But we have a lot of missing values in other variables. This is because each row corresponds to one beep, and since the data consists of three questionnaires, not all questions are answered in each beep.

## Initial cleaning and column renaming
Before continuing with the pre-processing, we will do some initial cleaning and make the columns more readable.
```{r print colnames, class.output="scrollable"}
colnames(data) # prints the column names
```

There are some columns that we will not need for our analysis (but may contain useful information in other cases). We can already remove them by using the `select()` function in the `dplyr` package. If we use the `-` or `!` sign before listing the columns, we select everything **except** those columns:

```{r remove columns, message = FALSE}
library(dplyr)

# We provide the function with a vector with the column names we want to remove
data <- data |> 
  select(-c(
    "legacyCode", "alias", "initials", "scheduledBeepId", "sentBeepId", "accountCode", 
    "reminderForOriginalSentBeepId", "originalTimeStampSent", "questionListLabel", 
    "timeZoneOffset", "fromProtocolName", "SWLS_intro_basic", 
    "BFI_neuroticism_intro_basic", "intake_outro_basic", "main_outro_basic",
    "evening_questionnaire_warning_basic", "evening_outro_basic"
  )) 
```

Note: in this case, we are removing the column `originalTimeStampSent` because in our experiment, we did not have reminders. In case of reminders, the `originalTimeStampSent` contains the time stamp for the first notification and `timeStampSent` contains the time stamp for the reminder. 

Once we have removed some columns, we can rename the rest. Since we are working with `r ncol(data)` columns, changing each column name manually would be very time-consuming. 

To avoid doing this, we may want to check the column names and see if there is a pattern that we can use to make our task easier. In this case, since our questionnaire was implemented in m-Path, the column names consist of the label we gave in questionnaire creation, as well as a suffix indicated the type of question (For example: `age_open` has the suffix `_open`). Knowing this, we can remove some of these suffixes in all the columns that have them.

An example of this is the Multiple choice questions (that end in `_multipleChoice`). We can remove these using the `gsub()` function. In this function, we supply the column names, specify the pattern we want to replace (`_multipleChoice`), and the replacement (`""`, an empty string).

```{r rename columns using gsub}
patterns <- c(
  "_yesno$", # removes _yesno, but only if it is at the end of the string (using $) 
  "_multipleChoice", # Remove _multipleChoice suffix
  "_sliderN.*", # Remove _slider suffixes and everything after it
  "_open", # Remove _open
  "context_" # Remove context_ 
)

# Merge them into one string that we can use a regular expression
patterns <- paste0("(", paste(patterns, collapse = "|"), ")")

colnames(data) <- gsub(
  pattern = patterns, 
  replacement = "",
  x = colnames(data)
)
```

**Warning**: cleaning column names in this way may result in duplicated column names For example: if there was a column called `slider_happy_sliderNegPos`, we would end up with two columns named `slider_happy`, because of the column `slider_happy_sliderNeutralPos`. This can be a problem, so it is important to be aware of this and maybe check for duplicated column names after cleaning them.

```{r check for duplicated column names}
# checking for duplicated column names
anyDuplicated(names(data))
```
We have no duplicated column names as a result of the previous renaming.

----

Now, we have removed some suffixes and our column names are less cluttered. We can rename the rest of the columns manually with `rename()`. Note that this is not necessary, but we will use these renaming standards in this guide.

```{r renaming columns manually}
data <- data |> 
  rename(
    participant = "connectionId", # renaming connectionId to participant
    gender = "gender_index",
    questionnaire = "questionListName",
    scheduled = "timeStampScheduled",
    sent = "timeStampSent",
    start = "timeStampStart",
    stop = "timeStampStop",
    step_count = "step_count_steps",
    phone_server_offset = "deltaUTC",
    evening_stressful = "evening_yesno_stressful",
    evening_positive = "evening_yesno_positive"
  )
```

### Replace participant values with a participant number
Our participant identifier is the column `participant`, which contains IDs such as `r unique(data$participant)[1]`. We can replace these IDs with a participant number that goes from 1 to the number of participants. 

But first, we should check that there are no `NA`s in this column:
```{r Check for NAs in participant column}
# first check that there are no missing values in the participant variable
anyNA(data$participant)
```

There are no `NA`s in the participant variable, so we can safely replace it with a participant number. We can use the function `match()` to replace the participant alias with its index in `unique(data$participant)`. This will yield us with participant numbers that go from 1 to the number of participants (which is `length(unique(data$participant))`).

```{r replace participant values with participant number}
# print unique values in data$participant before match
unique(data$participant) 

# matches the values in data$participant with the unique values in data$participant and
# returns the index of the match
data$participant <- match(data$participant, unique(data$participant)) 

# print unique values in data$participant after match
unique(data$participant) 
```

## Making composite variables
After having done some initial cleaning, we can create composite variables. In our study, participants completed a `main_questionnaire`, an `evening_questionnaire` and a `Consent and intake questionnaire`. In this last one, participants provided information that does not change over time.

```{r print different questionnaires in the study}
# to check which different questionnaires are part of the dataset:
unique(data$questionnaire) 
```
In the intake questionnaire, participants were asked about: 

1. Their age and gender 
2. Their level of Neuroticism, according to the Neuroticism subscale of the Big Five Inventory (BFI) 
3. Satisfaction with Life Scale (SWLS). 


We can create composite variables for these 2 scales and add them to the main dataset.

```{r create data frame with only intake questionnaire rows}
 # Create a data frame with only intake questionnaire rows
intake_data <- filter(data, questionnaire == "Consent and intake questionnaire")

# check that everyone that is in data is also in intake_data -> everyone completed intake survey
setequal(data$participant, intake_data$participant)
```

Now that we have a new data frame with only the intake questionnaire rows, we create the **composite variable for the SWLS**, which is the sum of its 5 items:

```{r composite variable for SWLS}
# create composite variables
# For life Satisfaction: sum of the 5 items
intake_data <- intake_data |> 
  mutate(life_satisfaction = rowSums(pick( 
    "SWLS_1_likert",
    "SWLS_2_likert",
    "SWLS_3_likert",
    "SWLS_4_likert",
    "SWLS_5_likert"
  )))

# Alternatively, if you have many columns you need to sum, you can best do so using a
# regular expression:
intake_data <- intake_data |> 
  mutate(life_satisfaction = rowSums(pick(matches("SWLS_[1-5]_likert"))))
```

For the **composite variable for neuroticism:**, we take the mean of the 8 items. However, the variables named with an "R" after the question number (like `"BFI_neuroticism_9R_multipleChoice_likert"`) need to be reversed.
```{r composite variable for BFI}
# For each column that matches our regular expression, We apply the function (`\(x)` is a
# shorthand for `function(x)`) `6 - x`, to reverse the scores of the items. The regular
# expression is as follows: The literal string "BFI_neuroticism_` followed by at least one
# (that"s where the `+` sign is for) number (the `\\d` character) followed by the letter R
# and then the literal string "_likert". This should match all of the reverse-keyed BFI
# items. Optionally, we can reencode the names using a `glue::glue()` expression, where we
# can insert code to run the function `gsub()` to replace the letter "R" with nothing, to
# match the names of the other BFI items.
intake_data <- intake_data |> 
    mutate(across(
        .cols = matches("BFI_neuroticism_\\d+R_likert"),
        .fns = \(x) 6 - x,
        .names = "{gsub('R', '', .col)}"
    )) 

# We can then calculate the mean of the BFI items using a regular expression as before.
# The function `matches()` picks all the columns corresponding to the BFI, but only the 
# reversed ones (it does not pick columns with an R like BFI_neuroticism_9R_likert)
intake_data <- intake_data |> 
  mutate(neuroticism = rowMeans(pick( 
    matches("BFI_neuroticism_[4,9,14,19,24,29,34,39]_likert")
  )))

```

Now that we created the composite variables for the intake questionnaire, we can join them to the main dataset. This also means that we can remove the rows corresponding to the intake questionnaire from the main dataset, as we have already extracted the information we needed.

```{r}
# Select only relevant columns for `intake_data`
intake_data <- intake_data |> 
  select(
    "participant", "gender", "gender_string", "age", 
    "life_satisfaction", "neuroticism"
  )

# First, remove the rows corresponding to the intake questionnaire from the main dataset
# as well as the column from the intake questionnaire
data <- data |> 
  filter(questionnaire != "Consent and intake questionnaire") |> 
  select(-"consent_yesno":-"BFI_neuroticism_39_likert") 

# Then, match the intake data with the composite scores back to the main dataset by using
# the participant number as a key
# Also relocate the columns from the intake data to be placed before the ESM columns (but
# after the "default" columns)
data <- data |> 
  left_join(intake_data, by = "participant") |> 
  relocate("gender":"neuroticism", .before = "slider_happy")
```

## Checking for duplicated variables
Following the [ESM Preprocessing Gallery guidelines for duplication](https://preprocess.esmtools.com/pages/40_Duplication.html), we will check for the following three types of duplication:

**1. Duplicated rows:** two rows that are exactly identical. We do not have any:
```{r check for duplicated rows}
# Returns 0 if there are no duplications, or the indices of the duplicated rows otherwise
anyDuplicated(data) 
```

**2. Duplicated answers:** we want to check whether any observation have exactly the same answers. We do not have any:
```{r check for duplicated answers, warning = FALSE}
# Load the package `tidyr` to use `drop_na()` to remove missing values
library(tidyr)

duplicated_answers <- data |> 
  drop_na(start) |>  # remove rows that correspond to unanswered beeps
  group_by(pick("slider_happy":last_col())) |> # Group by all the items
  filter(n() > 1) # check for duplicated answers in that column

duplicated_answers
```

**3. Duplicated time stamps** we will check that the same participant does not have duplicated time stamps.

First, we will check for duplicates in the `sent` variable.

```{r check for duplicated time stamps}
# Different participants can correctly have the same time stamp
# so we will just check that the same participant does not have duplicated time stamps:
duplicated_sent <- data |> 
  group_by(participant, sent) |> 
  filter(n() > 1) 

duplicated_sent
```
It seems that one participant answered the evening questionnaire twice. In our case, this was possible because participants were allowed to fill the evening questionnaire multiple times if they clicked on the "repeat questionnaire" button in the app.

We can just remove the questionnaire that was answered later, as follows:
```{r remove duplicated time stamp}
# For each participant and sent time, take the earliest `start` time (and thereby removing
# later `start` times). This will remove the duplicated time stamp.
data <- data |> 
  group_by(participant, sent) |>
  slice_min(start, n = 1, with_ties = FALSE) |> 
  ungroup()
```

Now, we can check that there are no duplicates in the `start` column:

```{r check for duplicates in the start column}
duplicated_start <- data |> 
  drop_na(start) |>  # remove rows that correspond to unanswered beeps
  group_by(participant, start) |> 
  filter(n() > 1)

nrow(duplicated_start) # no duplicated start time stamps!
```
There are no duplicates in `start`.

## First missingness analysis

It"s important to investigate and understand missing values as it can help us understand participants response patterns, and identify data collection errors. 

In our case, participants were not able to skip questions, so missing values may also indicate errors in the data collection process. However, we did have branching questions in the evening questionnaire, where participants were asked if they had had a stressful/positive event that day and were prompted to describe the event only if they answered "yes". If they answered "no", they were not asked, therefore, `NA` values in these columns are expected. 

Note that exploring `NA` values is different from exploring participant compliance (their proportion of answered beeps). We will explore participant compliance in a later step. 

First, we can use the `vis_miss()` function from the `visdat` package to visualize the missing values in the dataset. The x axis represents the variables in the dataset and the y axis represents the rows. The black cells represent present values, and the white cells represent missing values. 

We can see that there are some columns with a lot of missing values, which is expected since we are displaying data from two different questionnaires. We can also see that there are some participants that did not sign up with a "code".

```{r plot missing values}
library(ggplot2)
library(visdat)

# This plot makes more sense if the data is ordered by `participant` and `start`
data <- arrange(data, participant, start)

vis_miss(data) + 
  ggtitle("Missing values")
```

We have also seen that some columns may have all missing values. It would be interesting to check which columns they are, and remove them if they are not useful for the analysis.

```{r check which columns have all NA}}
# Create a helper function that checks whether all missing values are missing
all_na <- function(col) all(is.na(col))

# Get cols that have all NA
na_cols <- lapply(data, all_na) 
na_cols <- as.logical(na_cols)

# checking the names of these columns. We have 4 cols with all NA
names(data)[na_cols] 
```

The four columns with all `NA` are: `r names(data)[na_cols]`. These correspond to multiple choice questions where an "Answer value" was not provided during questionnaire creation. Therefore, it is completely expected that these columns are empty. We will remove them with:  

```{r remove columns with all NA}
data <- data[, !na_cols] # removing cols with all NA

# Tidyverse alternative
data <- select(data, -where(all_na))
```

We can also see that the missed beeps have `NA`s in the `start` variable, and the answered beeps do not. We can use this information to create an additional variable that indicates whether the beep was answered or not.

```{r create answered variable}
data <- data |> 
  mutate(answered = !is.na(start)) # missed beeps will be FALSE, answered beeps will be TRUE
```

## Reformat time stamps

The time stamps from m-Path are in [Unix time](https://en.wikipedia.org/wiki/Unix_time) but with respect to the local time zone of the participant. To work with them, we will reformat them to a more readable format. We will use the `timestamps_to_datetime` function from `mpathr`, that will put the dates in this format: `"%Y-%m-%d %H:%M:%OS"`. We are specifying the time zone as `"Europe/Brussels"` because we know our participants were in this time zone. However, if you are not merging the data with any other dataset, the timezone is not crucial and can be left out.

```{r reformat time stamps}
data <- data |> 
  mutate(across(
    .cols = c("scheduled", "sent", "start", "stop"),
    .fns = \(x) timestamps_to_datetime(x, force_tz = "Europe/Brussels")
  ))
```

Now that the dates are reformatted, we can create some other important time variables: 

1. We create a column `obs_n` that for each participant, shows the number of observations in the order they were sent (starting from 1 to 110, which is the total number of observations per participant). 

2. The column `day_n` shows the number of days since the first beep was sent for each participant.

3. The column `obs_n_day` shows the observation number within a day for each participant (the first beep of the day will be 1, until the last beep of the day: 11).

```{r create time variables, message = FALSE}
library(lubridate)

# Let"s first create a helper function to calculate the day number (1, 2, etc.) since the
# start of the study. By using `group_by()` before calling this function, the function
# is called each time with a vector of dates corresponding to the same participant.
day_number <- function(vec) {
  # Transform the vector to dates Note that lubridate::date()` takes into account the time
  # zone, while `as.Date()` does not.
  vec <- date(vec)
  
  # Get the first day in the vector
  day_one <- min(vec, na.rm = TRUE)
  
  # Calculate the difference in days, and add 1 to start from 1
  diffs <- difftime(vec, day_one, units = "days") + 1
  
  # Convert the difftime objects to integers
  as.integer(diffs)
}

# First sort the data by participant and sent time because ordering matters
data <- arrange(data, participant, sent)

# For each participant, calculate the total observation number. Since each beep is a row,
# we can do this using `row_number()`.
# Also for each participant, calculate the day number since the start of the study.
data <- data |> 
  group_by(participant) |> 
  mutate(obs_n = row_number()) |> 
  mutate(day_n = day_number(sent)) |>
  ungroup()

# Then calculate the observation number within a day for each participant, again using
# `row_number()`.  
# Create observation number within day
data <- data |>   
  group_by(participant, day_n) |> 
  mutate(obs_n_day = row_number()) |> 
  ungroup()

```

## Merging with external data sources

Here, we will show how to merge the current dataset with an external dataset. 

In the external dataset, we have data that corresponds to the average heart rate throughout the day (note: unlike the other data, the external data does not correspond to real data, it was simulated). 

```{r}
# Load the external dataset
external_data <- read.csv("external_dataset_bpm.csv")

# Check the dataset
head(external_data) 
```
The external dataset has the columns `code`, `day_n` and `bpm_day`, for each participant and for each day we have the mean heart rate. 

Since the value to link the two datasets is in `code`, we should check that the codes are in order (e.g. are there missing codes?). We can check that each code corresponds to one participant by examining the variable"s [coherence](https://preprocess.esmtools.com/pages/40_Check_variable_coherence.html). We can see here that one participant does not have a code, so we will not be able to get their heart rate data. But otherwise it seems like each code corresponds to one participant:

```{r}
distinct(data, participant, code) 
```

We can use the following code to merge it with the main dataset:

```{r merge with external data}
# We merge by code and by day because we have a heart rate mean for each participant and
# each day
data <- left_join(
  x = data,
  y = external_data, 
  by = c("code", "day_n")
) 
```

## Handling nested data

When participants can provide multiple choices to a question, `read_mpath()` stores these as vectors such as list columns of nested data, where each values is a vector`c(1,2,4)`:

| Participant   | day           | choice |
| ------------- | ------------- |------------------ |
| 1             | 1             | c(1, 2, 4)        |
| 1             | 2             | c(2, 3)           |
| 1             | 3             | c(4)              |


To deal with these responses and analyze them, we can convert the data to a **long format**: (where each choice is a separate row), like this: 

| Participant   | day           | choice |
| ------------- | ------------- |------------------ |
| 1             | 1             | 1                 |
| 1             | 1             | 2                 |
| 1             | 1             | 4                 |

We can also convert the data to a **wide format** (where each choice is a separate column). 

| Participant   | day           | choice_1| choice_2| choice_3|
| ------------- | ------------- |--- | --- | --- |
| 1             | 1             | 1  | 2   | 4   |

The following data exemplifies how to convert the these kind of columns both to a long and to a wide format. Using our column `evening_activity_index`, which contains vectors of which activities people had done during a specific day:

```{r create activity data}
# Delete rows with an NA in this column
activity_data <- data |> 
  select("participant", "day_n", "evening_activity_index") |> 
  filter(!is.na(evening_activity_index))

activity_data
```

Note that in the above code, we delete rows with `NA` in the column `evening_activity_index`. In our case, participants were **not** allowed to leave this question blank, so `NA`s indicate unanswered beeps. In other cases, `NA`s may indicate that the person reported doing none of the activities listed, so it maybe would not be a good idea to delete these rows, as they are still informative.

### Long format
```{r convert to long format}
# Convert to long format using unnest()
long_data <- activity_data |>  
  unnest(evening_activity_index)

long_data
```

### Wide format
``` {r convert to wide format}
wide_data <- activity_data |> 
  unnest_wider(evening_activity_index, names_sep = "_")

wide_data
```

Another option for a wide data frame is to have binary columns corresponding to an choice. Like this: 

| Participant   | day           | choice_1| choice_2| choice_3|
| ------------- | ------------- |--- | --- | --- |
| 1             | 1             | 0  | 1   | 0   |
| 2             | 1             | 1  | 1   | 1   |

In this table, participant one chose choice 2, but didn"t choose choice 1 or 3, while participant 2 chose all three options. This can be done with the following code:

```{r convert to wide format (with binary variables)}
data_wide_binary <- activity_data |> 
  unnest(evening_activity_index) 

data_wide_binary <- data_wide_binary |> 
  mutate(activity = paste0("activity_", evening_activity_index)) |> 
  pivot_wider(
    names_from = "activity",
    values_from = "evening_activity_index",
    values_fill = list(evening_activity_index = 0),
    values_fn = list(evening_activity_index = length)
  )

data_wide_binary
```


## Re-ordering columns

As a final step, we will re-order the columns using the `relocate` function from `dplyr`:

```{r re-order columns}
data <- data |> 
  relocate("obs_n", "day_n", "obs_n_day", "answered", "bpm_day", .before = "gender")
```

# Step 2 : Design and sampling scheme

In this [step](https://preprocess.esmtools.com/framework.html#step-2-design-and-sampling-scheme), we explore the design and sampling scheme of the study. The main goal is to examine to what extent the data collection process went as expected, and to identify potential issues that could motivate data exclusion. We mainly will check the coherence of the time stamps, the sent beeps and the duration of the study.

## Coherence time stamps and observations order

In the following sections, we perform some logical tests to ensure the coherence of the time stamps and the observations. For example: we expect that for one observation, the scheduled time should always be before the sent time. Having beeps where this is not the case could indicate an error in the data collection process. For more information on time stamp coherence and how to check it, see the [ESM Preprocessing Gallery](https://preprocess.esmtools.com/pages/50_Coherence_timestamps_obs.html).

### Coherence within observations

Within a single observation, we expect that the scheduled time is before the sent time, the sent time is before the start time, and the start time is before the stop time. We will check this for all observations. 

```{r coherence within observation}
# Checking that scheduled < sent < start < stop

# check if any scheduled time is after the sent time
any(data$scheduled > data$sent & !is.na(data$sent)) 

# check if any sent time is after the start time
any(data$sent > data$start & !is.na(data$start)) 

# check if any start time is after the stop time
any(data$start > data$stop & !is.na(data$stop)) 
```
It all returns `FALSE`, which means that all observations are in the expected order.

If some observations were not in the expected order, this could be due to participants changing time zones, or changing from summer to winter times (or the other way around).

### Coherence between observations

We should also verify that the time stamps are in the correct order between observations. We expect that the scheduled time of the current observation is before the scheduled time of the next observation, and the same for the sent, start, and stop times. 

However, it may be that participants answered the 6th beep before the 5th beep, due to close beep times and overlapping expiration times. In this case, maybe the order of the observations could be reversed, so that observation 5 becomes observation 6. 

To check for coherence between observations, we order the data frame according to one of our time variables, and check for issues between consecutive observations.

```{r coherence between observations}
# check if the scheduled time of the current observation is after the scheduled time of
# the previous observation
# show only rows where one of these issues is present
data |> 
  select(participant, "scheduled", "sent", "start", "stop") |> 
  arrange(participant, sent) |> 
  group_by(participant) |> 
  mutate(
    sched_lag_issue = lag(scheduled) > scheduled, 
    sent_lag_issue = lag(sent) > sent,
    start_lag_issue = lag(start) > start,
    stop_lag_issue = lag(stop) > stop
  ) |> 
  filter(sched_lag_issue | sent_lag_issue | start_lag_issue | stop_lag_issue) 
```

We have a row that shows a `start_lag` issue, upon further inspection, we see that this is because the participant filled a main questionnaire beep just after the evening questionnaire. 

This is okay, because in the evening questionnaire participants answer about their whole day, and in the "main questionnaire" beep they answer about how they feel in that moment. 

## Duration of the study per participant

We will now check the duration of the study by plotting the earliest and latest sent date. We expect that the duration of the study is the 10 days for everyone.

```{r study duration per participant, message = FALSE, warning = FALSE}
# Load the `ggalt` package for `geom_dumbbell`
library(ggalt)

# Calculate the beginning and end time of the study for each participant
study_duration <- data |> 
  group_by(participant) |> 
  summarise(
    from = min(sent, na.rm = TRUE), 
    to = max(sent, na.rm = TRUE)
  ) |> 
  mutate(participant = as.factor(participant)) # For ggplot

# Create a plot showing the study run time for each participant
study_duration |> 
  ggplot(aes(
    x = from, 
    xend = to, 
    y = participant
  )) + 
  geom_dumbbell(color = dark_mpath_palette[1], size = 0.75) +
  scale_x_datetime(date_breaks = "1 month", date_labels = "%B %y") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  labs(
    title = "Duration of the study per participant",
    x = "Time",
    y = "Participant"
  )

# Verify that there are 10 days for all participants
data |>
  group_by(participant) |> 
  summarise(max_days = max(day_n))
```

## Number of beeps **sent** per participant
All participants have the same number of beeps sent, as expected:

```{r number of sent beeps}
n_sent <- data |> 
  drop_na(sent) |> 
  group_by(participant) |> 
  summarize(n = n()) 

# Create a bar chart with the number of beeps sent per participant
n_sent |> 
  ggplot(aes(
    x = factor(participant), # factor() is needed to make them into categories
    y = n
  )) +
  geom_col(position = "dodge", fill = dark_mpath_palette[2]) +
  labs(
    title = "Number of beeps sent per participant",
    x = "Participant",
    y = "Number of beeps"
  )
```

## Delay between two consecutive beeps
Most delays are around 1 hour because that"s how we spaced the beeps during the day.
The delays at around 10 hours correspond to the delay between the last beep of the day (evening questionnaire) and the first beep of the next day.

```{r delay between two consecutive beeps, message = FALSE, warning = FALSE}
df_int <- data |>
  arrange(participant, sent) |>
  group_by(participant) |>
  mutate(delay = difftime(lead(sent), sent, units = "hours")) 

df_int |> 
  ggplot(aes(x = delay)) +
  geom_histogram(bins = 100, fill = dark_mpath_palette[3]) + 
  labs(
    title = "Delay between two consecutive beeps",
    x = "Delay between two consecutive beeps (hours)",
    y = "Count"
  )
```

## Conclusions: Design and sampling scheme

In general, we did not find any issues with the experimental design: 

* The time stamps are coherent.
* The number of beeps sent is equal for all participants, which in our case was intended (note that in some experiments, participants may receive different beeps depending on their experimental group, or other variables. In which case an equal number of beeps per participant would be a problem).
* The delays between beeps are as expected.
* The duration of the study per participant is also consistent (we expected an equal duration of 10 days per participant). 

We can now move on to the next steps of the pre-processing.

Note: we followed steps that were relevant for our study design, for a more comprehensive overview of possible checks for the sampling
and study design, see the [ESM Preprocessing Gallery](https://preprocess.esmtools.com/).

# Step 3: Participants response behaviors

In this step, we want to look more closely at participants" responses. We will look at whether participants seemed to follow the sampling scheme correctly, and whether there are any response patterns that could reduce data quality. We primarily will look at the sampling scheme per participant, the delay to fill beeps, the time of answered and missed beeps, and participant compliance. 

For a more comprehensive overview of possible checks for this step, see the [ESM Preprocessing Gallery](https://preprocess.esmtools.com/).

## Sampling scheme per participant

### Beep level
With the plot below, we can explore whether there are patterns in participant"s response rates throughout the study. 

In the following plot you can see the number of beeps answered per participant, per observation. The vertical lines separate the days. 

Participant 1 and 16 seemed to answer more beeps at the start of the study than later on, and there are some considerable gaps for some participants (e.g. participant 2). But otherwise there"s no clear pattern.

```{r sampling scheme for beeps}
data |> 
  filter(answered) |>  # filtering by answered beeps, another option is drop_na(start)
  ggplot(aes(x = obs_n, y = factor(participant))) +
  geom_point(
    size = 1.5, 
    col = dark_mpath_palette[1]
  ) +
  geom_vline(
    xintercept = seq.int(from = 11.5, to = max(data$obs_n), by = 11), 
    color = mpath_palette[3], 
    alpha = 0.5
  ) +
  labs(
    title = "Answered beeps per participant",
    x = "Observation number",
    y = "Participant"
  )
```

## Delay to start and to fill

We will now look at the delay between when participants received a beep and when they actually answered it (the delay in starting the beep), and how long it takes participants to fill the beep. 

We will plot the delay to start and to fill separating per questionnaire, this is because the two different questionnaires had a different expiration time. We can see that most delays to answer are quite small. Some answers for the evening questionnaire took a long time, this was because the evening questionnaire had an expiration of 3 hours, while participants were only able to answer beeps for the main questionnaire in the first 30 minutes. 

```{r delay to start and fill, warning = FALSE}
data <- data |> 
  mutate(
    delay_start_min = difftime(start, sent, units = "mins"),
    delay_end_min = difftime(stop, start, units = "mins") 
  ) 

data |> 
  filter(answered)  |> 
  ggplot(aes(x = delay_start_min, fill = questionnaire)) +
  geom_histogram(bins = 100, alpha = 0.7, position = "identity") + 
  scale_fill_manual(values = dark_mpath_palette) +
  labs(
    title = "Delay to start per questionnaire",
    x = "Delay to start (minutes)",
    y = "Count"
  )
```

## Time of answered/missed beeps

Here, we will explore the time of answered and missed beeps. If these histograms are very different, it may indicate that participants are missing beeps at certain times of the day (for example, it could be that participants miss more beeps in the morning than in the afternoon). 

The plots look very similar. We can see that the last beeps were sent at around 22h, but there are answered beeps as late as 1h in the night. This is because the expiration date for the evening questionnaire was set at 3 hours, so some participants may have answered these beeps quite late. The expiration for the rest of the beeps was around 30 minutes.

```{r time of answered and missed beeps, message = FALSE, warning = FALSE}
# To use the function `date_breaks()`
library(scales)

# Hour of day from answered beeps
# Extract the hour, minute and seconds from the `start` time with `format()`.
data |> 
  filter(answered) |> 
  mutate(start = format(start, format = "%H:%M:%S")) |> 
  ggplot(aes(x = hms(start))) +
  geom_histogram(bins = 100, fill = dark_mpath_palette[1]) +
  scale_x_time(
    limits = hms(c("00:00:00", "24:00:00")), 
    breaks = date_breaks("2 hours"),
    labels = function(x) strftime(x, format = "%H:%M")
  ) +
  labs(
    title = "Time of answered beeps",
    x = "Time",
    y = "Count"
  )

# Hour of day of missed beeps
# Extract the hour, minute and seconds from the `sent` time with `format()`.
data |> 
  filter(!answered) |> 
  mutate(sent = format(sent, format = "%H:%M:%S")) |> 
  ggplot(aes(x = hms(sent))) +
  geom_histogram(bins = 100, fill = dark_mpath_palette[2]) +
  scale_x_time(
    limits = hms(c("00:00:00", "24:00:00")), 
    breaks = date_breaks("2 hours"),
    labels = function(x) strftime(x, format = "%H:%M")
  )+
  labs(
    title = "Time of missed beeps",
    x = "Time",
    y = "Count"
  )
```

## Compliance rate

Compliance is the proportion of answered beeps. It is important to have a look at this metric, to identify participants that have missed a lot of beeps. We can use the function `response_rate` from the `mpathr` package to calculate the response rate. 

```{r compliance rate, message = FALSE}
# Get the response rates
response_rates <- response_rate(
  data = data,
  valid_col = answered, 
  participant_col = participant
)

response_rates |>
  group_by(participant) |>
  ggplot(aes(x = participant, y = response_rate)) +
  geom_bar(stat = "identity", fill = dark_mpath_palette[3]) +
  labs(
    title = "Compliance per participant",
    x = "Participant",
    y = "Compliance (proportion of answered beeps)"
  )
```

Additionally, we can just print a summary of each participant and their compliance:

```{r print response rates}
print(response_rates)
```

We can see that some participants have a very low compliance rate (e.g. participant 1 with a compliance of 11%). We may want to exclude these participants from the analysis.

```{r filter out participants with low compliance}
# Remove participants with a response rate lower than 30%
low_response <- response_rates |>
  filter(response_rate < 0.3) |>
  pull("participant") # Pull out a variable as a vector

data <- data |>
  filter(!(participant %in% low_response))
```

### Detecting dishonesty

In cases where participants receive incentives based on how many questionnaires they filled, they could manually change the time on their phone to fill in older questionnaires. In order to detect this, we have the column `phone_server_offset`, which is the difference between the phone time and the server time. 

If participants change the time on their phone, this column will show a large difference. We can check if there are any participants with a large difference in the `phone_server_offset` column. 

```{r check phone-server offset, warning=FALSE}
data |>
  mutate(phone_server_offset = abs(phone_server_offset / 60)) |>
  ggplot(aes(x = abs(phone_server_offset))) +
  geom_histogram(
    bins = 100, 
    alpha = 0.7, 
    position = "identity", 
    fill = mpath_palette[1]
  ) +
  labs(
    title = "Difference between phone and server time",
    x = "Phone-server offset (minutes)",
    y = "Count"
  )
```

We can see that the maximum difference is around 3 minutes. Since this is not a large difference, it seems like participants didn"t change the time on their phone during the study.

## Conclusions: Participants response behaviors

In this section, we examined participants" response behaviors and identified some patterns. 
For example, we found and removed participants with a very low compliance rate.

For more guidelines on how to conduct similar checks, see [ESM Preprocessing Gallery](https://preprocess.esmtools.com/).

# Step 4: Compute and transform variables

In this step we will compute important variables to prepare the data for our analysis. 

We will conduct the following two analyses:

1. **Analysis 1**: Do participants have more negative affect when they are alone?
2. **Analysis 2**: Is the evening-reported anxiety level predicted well with a combination of the mean anxiety levels and the maximum anxiety level experienced throughout the day?

## Data preparation for analysis 1
### Computing affect scores

For the first analysis, we need to compute a measure of negative affect. This will be the mean of the sad, angry, anxious, and tired sliders. 

```{r compute negative affect score}
data <- data |> 
  mutate(negative_affect = rowMeans(pick(
    "slider_sad", "slider_angry", "slider_anxious", "slider_tired"
  )))
```

### Computing binary variables from multiple choice questions

For the first analysis, we also need to create a binary variable that indicates whether the participant was alone or not. We can use the `company_string` variable to create it. 

The `company_string` column contains the response options that indicate the participant's social status: 

* Option 1: "Alone"
* Option 2: "With one person I know"
* Option 3: "With multiple people I know"
* Option 4: "With one or more people I don"t know"

We will create a new variable called `alone` that is `TRUE` if the participant was alone, and `FALSE` if they were not. 

```{r create alone variable}
data <- data |>
  mutate(alone = company_string == "Alone") 
```

This is the only transformation we need for the first analysis. We can save away the data from this analysis to `data_analysis_1`, where we also filter out unanswered beeps (or beeps that do not correspond to the main questionnaire) and only keep the variables we need for the analysis. 

```{r create data for analysis 1}
data_analysis_1 <- data |> 
  filter(questionnaire == "main_questionnaire" & answered) |> 
  select("participant", "negative_affect", "alone")
```

## Data preparation for analysis 2
### Filtering out participants and days with small response rate
For the second analysis, we will eliminate participant"s data if they had less than 50% compliance rate:

```{r find participants with low compliance}
# Calculate which participants have a compliance rate of less than 50%
participants_to_rm <- response_rate(
  data = data, 
  valid_col = answered, 
  participant_col = participant
) |>
  filter(response_rate < 0.5) |> 
  pull("participant")

# these are the participants we will remove for the 2nd analysis
print(participants_to_rm) 
```
Now that we know which participants to remove, we just filter them out and save the resulting data frame to `data_analysis_2`.

```{r filter out participants for analysis 2}
# filters out participants that are present in participants_to_rm
data_analysis_2 <- data |>
  filter(!(participant %in% participants_to_rm)) 
```

Also, for every participant, if they answered less than 50% of the beeps on a given day, we will remove that day"s data from the analysis. This is important since we will take the mean, and we would not want to analyze means of very few values.

```{r filter out days with low compliance, warning = FALSE, message = FALSE}
days_below_50 <- data_analysis_2 |>
  group_by(participant, day_n) |> 
  summarize(na_prop = sum(answered) / max(obs_n_day)) |> 
  filter(na_prop < 0.5)

# Use an anti join to remove elements from `data_analysis_2` that match those in 
# `days_below_50`
data_analysis_2 <- data_analysis_2 |>
  anti_join(days_below_50, by = c("participant", "day_n")) 
```

### Computing the maximum and mean anxiety level

We will calculate the maximum and the mean anxiety level (in `slider_anxious`) experienced by each participant in each day. We can do this with the following code: 

```{r compute max and mean anxiety level}
data_analysis_2 <- data_analysis_2 |>
  group_by(participant, day_n) |>
  mutate(
    max_anxious = max(slider_anxious, na.rm = TRUE),
    mean_anxious = mean(slider_anxious, na.rm = TRUE)
  ) |> 
  ungroup() |>
  filter(questionnaire == "evening_questionnaire" & answered) |>
  select("participant", "day_n", "evening_slider_anxious", "max_anxious", "mean_anxious") 
```

# Step 5: Data exploration

Now, we will explore the data a bit more to get to know the distribution and characteristics of some important variables. 

## Correlation between negative affect variables
Since we are pooling together all the negative affect variables into a composite variable (negative affect), it"s interesting to see how related they are. We can quickly visualize the correlations between these variables in the plot below: 

```{r correlation between negative affect variables, message = FALSE}
library(GGally)

data |> 
  select("slider_anxious", "slider_sad", "slider_angry","slider_tired") |> 
  drop_na() |> # Drop all missing values
  ggpairs()
```

As expected, correlations are positive, but most correlations between the variables are rather weak. 

Along the diagonal, we can see the distribution of the variables. Most distributions are clearly skewed to the right. Which means that most of the time, participants report low levels of anxiety, sadness and anger. However, participants report higher levels of tiredness. 

## Alone vs. not alone

We could look at how often participants reported being alone. We can see that the proportion of time alone greatly varies between individuals. Some participants report being alone almost 90% of the time, while some others are accompanied mostly 90% of the time. 

```{r alone vs. not alone plot}
alone_data <- data |>
  drop_na(alone) |> 
  mutate(company_string = factor(company_string, levels = c(
    "Alone", 
    "With one person I know", 
    "With multiple people I know", 
    "With one or more people I don't know"
  ))) |> 
  count(participant, company_string)
  
alone_data |> 
  ggplot(aes(
    x = participant,
    y = n,
    fill = company_string
  )) +
  geom_bar(position = "fill", stat = "identity") +
  scale_fill_manual(
    name = "Type of company",
    values = c(mpath_palette[c(1,3)], "#DB8908", mpath_palette[2])
  ) +
  labs(
    title = "Proportion of time alone or accompanied",
    x = "Participant",
    y = "Count"
  )
```

For the analysis, we will pool together reports of being with multiple people, or being with only one person. We will also consider being with one or more people that the participant does not know as being accompanied. 

## Emotion variables

We can also have a look at the distribution of the emotion sliders. We can mainly see that the negative emotions (angry, anxious, sad and tired) tend to be skewed to the right, which means that most of the time participants report low levels of these emotions. "Tired" seems to be an exception to this trend. Meanwhile, the positive emotions (happy, relaxed and energetic) tend to be skewed to the left, which means that most of the time participants report high levels of these emotions. 

```{r plot distribution of emotion variables, warning = FALSE, message = FALSE}
data |> 
  pivot_longer("slider_happy":"slider_tired") |> 
  ggplot(aes(x = value)) +
  geom_histogram(aes(y = after_stat(density)), alpha = 0.7) + 
  geom_density(alpha = 0.5) +
  facet_wrap(vars(name), scales = "free_y")
```

# Step 6: Analysis
## Question 1: Do participants have more negative affect when they are alone?

We will assess this question with a mixed model, to account for the random effect of participants. We will use the following formula: 

$$\text{negative affect ~ alone + (1 + alone | participant)}$$
With this formula, we specify an intercept for every participant, as well as random slopes for `alone`.

```{r analysis 1 model, message = FALSE}
library(lme4)

model_1 <- lmer(
  formula = negative_affect ~ alone + (1 + alone | participant), 
  data = data_analysis_1
)
```

Before looking at the results, we should check that our mixed model"s assumptions are met. In our case, it does not make sense to look at linearity because our only predictor (`alone`) is a binary variable. However, we can check for homoscedasticity and normality of residuals: 

**Homoscedasticity**: We can check for homoscedasticity (also known as the homogeneity of variance) by using a function of the `performance` package which is part of the larger framework of `easystats`. While the Breusch-Pagan test that is run by `check_heteroscedasticity()` was significant ($p<.001$), a visual inspect tells us that there is only a very minor overall trend in the variance of the residuals, which is unlikely to influence the results.

```{r homoscedasticity analysis 1, message = FALSE}
library(performance)

check_heteroscedasticity(model_1)
plot(check_heteroscedasticity(model_1))
```

**Normality**: We can also check for normality of the residuals by using the `check_normality()` function. The Shapiro-Wilk test that is run by this function yielded a significant result ($p<.001$). A visual inspection shows that the residuals are not normally distributed for the lower quantiles and are slightly higher in the upper quantiles. 

```{r normality analysis 1}
check_normality(model_1)
plot(check_normality(model_1))
```

We can now check the results of the model:

```{r results analysis 1, message = FALSE}
summary(model_1) 

# Chi-square test to see if the effects are different from 0
library(car)
Anova(model_1)
```

From the results, we can see that the effect of being alone on negative affect is not significant (*p* = `r round(Anova(model_1)[3],2)`). It does not seem like participants have more negative affect when they are alone. However, we are using a very small dataset, which results in very low power. 

We can visualize the effect by plotting the values of the negative affect for the groups (alone and not alone) as well as the mean values for each group.

```{r plot analysis 1 calculation, warning = FALSE}
data_analysis_1$alone <- as.factor(data_analysis_1$alone)
levels(data_analysis_1$alone) <- c("Not Alone", "Alone")

data_analysis_1 |> 
  ggplot(aes(x = alone, y = negative_affect)) +
  geom_jitter(
    width = 0.07, 
    height = 0, 
    alpha = 0.2, 
    size = 2, 
    color = mpath_palette[1]
  ) +
  stat_summary(
    geom = "point", 
    fun = mean, 
    color = mpath_palette[2], 
    size = 2.5
  ) + 
  stat_summary(
    mapping = aes(group = 1),
    geom = "line",
    fun = mean, 
    color = mpath_palette[2], 
    linewidth = 1
  ) +
  stat_summary(
    geom = "errorbar",
    fun.data = mean_se, 
    width = 0.04, 
    color = mpath_palette[2]
  ) +
  labs(
    title = "Negative Affect by Alone",
    x = "Alone",
    y = "Negative Affect"
  ) +
  theme_minimal()
```

Alternatively, we can visualize this using the `modelbased` package which is part of `easystats`.

```{r plot analysis 1}
library(modelbased)

estimate_means(model_1, by = "alone") |> 
  plot(
    point = list(color = mpath_palette[1]), # Customise some of the aesthetics
    line = list(color = mpath_palette[2]),
    pointrange = list(color = mpath_palette[2])
  ) +
  theme_minimal() +
  labs(
    title = "Negative Affect by Alone",
    x = "Alone",
    y = "Negative Affect"
  )
```

## Question 2: Is the evening-reported anxiety level predicted well with the mean and the maximum anxiety level?

In this second analysis, we want to see whether the overall anxiety levels throughout the day (as reported in the evening questionnaire) can be well predicted by the average anxiety levels and the maximum anxiety levels experienced throughout the day. We will use the following model formula: 

$$\text{anxiety (evening) ~ mean(anxiety) + max(anxiety) + (1 | participant)}$$

```{r analysis 2 model}
model_2 <- lmer(
  formula = evening_slider_anxious ~ mean_anxious + max_anxious + (1 | participant), 
  data = data_analysis_2
)
```

Before looking at the results, we should check that our mixed model"s assumptions are met: 

**Linearity**: the points fall roughly along a straight line, so the linearity assumption is met.

```{r linearity analysis 2, warning = FALSE, message = FALSE}
check_collinearity(model_2)
plot(check_collinearity(model_2))
```

**Homoscedasticity**: there is no clear pattern in the residuals vs. fitted values plot, so the homoscedasticity assumption is also met.

```{r homoscedasticity analysis 2}
check_heteroscedasticity(model_2)
plot(check_heteroscedasticity(model_2))
```

**Normality**: it seems like there is more data located at the extremes of the distribution and less data at the center. However, the residuals are roughly normally distributed.

```{r normality analysis 2}
check_normality(model_2) 
plot(check_normality(model_2))
```

Now that we have checked the assumptions. We can move on to the results:

```{r results analysis 2}
summary(model_2)
Anova(model_2)
```

Both the mean and maximum anxiety level are significant predictors of the evening-reported anxiety. Going further, we may wonder how well our model predicts the evening-reported anxiety levels. For this, we can compute the $R^2$. We can use the `rsq` package, which implements a method for calculating it in mixed models. 

The $R^2$ of mixed models usually comes unpacked into three different values: 

* The proportion of variance explained by both the fixed and random effects, in `$model` (it is the sum of the two $R^2$ below).
* The proportion of variance explained by the fixed effects, in `$fixed`.
* The proportion of variance explained by the random effects, in `$random`.

Since our random effects are just to control for the effect of different participants. We mainly want to look at the $R^2$ in `$fixed`. 

```{r r2 analysis 2}
library(rsq)

rsq.lmm(model_2)
```
<!-- We can see that that the fixed effects explain `r round(rsq.lmm(model_2)$fixed * 100, 2)`% of the variance in the evening-reported anxiety levels.  -->

## Analysis: Conclusion
In this small analysis we assessed whether being alone influenced negative affect, and whether the mean and maximum anxiety experienced throughout the day could predict the evening-reported anxiety level. 

We mainly found that being alone does not seem to lead to higher negative affect levels. Maybe the way we categorized being alone was not sensitive enough to capture the effect. For example, we categorized the response option of being with "multiple people I don"t know" as **not** being alone, but it would also make sense to categorize it as being alone.

In the second analysis, we found that the mean and maximum anxiety levels experienced throughout the day are significant predictors of the evening-reported anxiety level. This shows that both the general level of anxiety, as well as the magnitude of anxiety peaks affect the appraisal of overall anxiety throughout the day. 
